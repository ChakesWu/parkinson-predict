{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPuEl8fELh+1geuUJEJS5iu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChakesWu/parkinson-predict/blob/main/Parkinson_Rehabilitation_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Parkinson Rehabilitation System.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at:\n",
        "    https://colab.research.google.com/drive/your-drive-link\n",
        "\"\"\"\n",
        "\n",
        "# ==================== 环境配置 ====================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# 创建项目目录结构\n",
        "!mkdir -p \"/content/drive/MyDrive/Parkinson_Project/{data,models,results}\"\n",
        "\n",
        "# 安装依赖库（修复版本冲突）\n",
        "!pip install torch==2.0.1 scipy==1.10.1 neurokit2==0.2.4 matplotlib==3.7.1 -q\n",
        "\n",
        "# ==================== 数据生成模块 ====================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import signal\n",
        "import os\n",
        "import time\n",
        "\n",
        "def generate_base_dataset(samples=30000):\n",
        "    \"\"\"生成基准临床数据集（100Hz采样，5分钟数据）\"\"\"\n",
        "    np.random.seed(42)\n",
        "    fs = 100  # 采样频率\n",
        "    t = np.linspace(0, 300, samples)\n",
        "    tremor_freq = 4 + np.random.normal(0, 0.5)\n",
        "    finger_angle = 90 + 10 * signal.sawtooth(2 * np.pi * tremor_freq * t)\n",
        "    finger_angle += np.random.normal(0, 2, samples)\n",
        "    acceleration = 0.8 * np.sin(2 * np.pi * 0.3 * t) * np.exp(-0.005*t)\n",
        "    acceleration += 0.1 * np.random.randn(samples)\n",
        "    emg_bursts = np.zeros(samples)\n",
        "    for i in range(0, samples, 2000):\n",
        "        burst = 0.5 * np.abs(signal.hilbert(np.random.randn(500)))\n",
        "        emg_bursts[i:i+500] = burst\n",
        "    emg = 0.4 * np.abs(signal.hilbert(np.random.randn(samples))) + emg_bursts\n",
        "    labels = np.where(\n",
        "        (np.std(finger_angle) > 8) &\n",
        "        (np.mean(emg) > 0.45) &\n",
        "        (np.max(acceleration) < 1.2),\n",
        "        1, 0\n",
        "    )\n",
        "    df = pd.DataFrame({\n",
        "        'timestamp': t,\n",
        "        'finger_angle': finger_angle,\n",
        "        'acceleration': acceleration,\n",
        "        'emg': emg,\n",
        "        'parkinson_label': labels\n",
        "    })\n",
        "    df.to_csv(\"/content/drive/MyDrive/Parkinson_Project/data/base_data.csv\", index=False)\n",
        "    print(\"基准数据集已生成，包含样本数:\", len(df))\n",
        "    return df\n",
        "\n",
        "def generate_custom_data(samples=3000):\n",
        "    \"\"\"生成用户自定义数据（50Hz采样，模拟设备采集）\"\"\"\n",
        "    np.random.seed(int(time.time()))\n",
        "    t = np.linspace(0, 300, samples)\n",
        "    finger_angle = 85 + 12 * signal.sawtooth(2 * np.pi * 5.5 * t)\n",
        "    finger_angle += np.random.normal(0, 3, samples)\n",
        "    acceleration = 0.6 * np.sin(2 * np.pi * 0.25 * t) * np.exp(-0.004*t)\n",
        "    acceleration += 0.15 * np.random.randn(samples)\n",
        "    emg = 0.5 * np.abs(signal.hilbert(np.random.randn(samples)))\n",
        "    spike_indices = np.random.choice(samples, 50, replace=False)\n",
        "    emg[spike_indices] += 0.8\n",
        "    df = pd.DataFrame({\n",
        "        'timestamp': t,\n",
        "        'finger_angle': finger_angle,\n",
        "        'acceleration': acceleration,\n",
        "        'emg': emg,\n",
        "        'parkinson_label': 1\n",
        "    })\n",
        "    df.to_csv(\"/content/drive/MyDrive/Parkinson_Project/data/custom_data.csv\", index=False)\n",
        "    print(\"自定义数据集已生成，包含样本数:\", len(df))\n",
        "    return df\n",
        "\n",
        "# ==================== 特征工程模块 ====================\n",
        "def kinematic_feature_engineering(df):\n",
        "    \"\"\"运动学特征增强（最终生成9个特征，并保留标签列）\"\"\"\n",
        "    df['angle_velocity'] = np.gradient(df['finger_angle'], df['timestamp'])\n",
        "    df['angle_acceleration'] = np.gradient(df['angle_velocity'], df['timestamp'])\n",
        "    freqs, psd = signal.welch(df['emg'], fs=100, nperseg=512)\n",
        "    df['emg_peak_freq'] = freqs[np.argmax(psd)]\n",
        "    df['emg_psd_ratio'] = psd[(freqs > 10) & (freqs < 35)].sum() / psd.sum()\n",
        "    features = [\n",
        "        'finger_angle', 'acceleration', 'emg',\n",
        "        'angle_velocity', 'angle_acceleration',\n",
        "        'emg_peak_freq', 'emg_psd_ratio'\n",
        "    ]\n",
        "    for feat in features:\n",
        "        df[feat] = df[feat].replace([np.inf, -np.inf], np.nan)\n",
        "        df[feat] = df[feat].fillna(df[feat].mean())\n",
        "    df[features] = (df[features] - df[features].mean()) / df[features].std()\n",
        "    df[features] = df[features].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "    df['rolling_angle_var'] = df['finger_angle'].rolling(window=100, center=True).var().fillna(0)\n",
        "    final_features = [\n",
        "        'finger_angle', 'acceleration', 'emg',\n",
        "        'angle_velocity', 'angle_acceleration',\n",
        "        'emg_peak_freq', 'emg_psd_ratio',\n",
        "        'rolling_angle_var', 'timestamp',\n",
        "        'parkinson_label'\n",
        "    ]\n",
        "    return df[final_features]\n",
        "\n",
        "# ==================== 模型架构 ====================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class PretrainedBioEncoder(nn.Module):\n",
        "    \"\"\"8通道输入版本（对应8个特征）\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(8, 32, 5, padding=2),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Conv1d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1)\n",
        "        )\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=8,\n",
        "            hidden_size=64,\n",
        "            bidirectional=True,\n",
        "            num_layers=2,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # CNN 处理 [batch_size, channels, time]\n",
        "        cnn_feat = self.cnn(x).squeeze(-1)\n",
        "        # LSTM 处理 [batch_size, time, input_size]\n",
        "        lstm_input = x.permute(0, 2, 1)  # 从 [batch_size, 8, 3000] 转为 [batch_size, 3000, 8]\n",
        "        lstm_out, _ = self.lstm(lstm_input)\n",
        "        lstm_feat = lstm_out[:, -1, :]\n",
        "        return torch.cat([cnn_feat, lstm_feat], dim=1)\n",
        "\n",
        "class TransferLearningModel(nn.Module):\n",
        "    \"\"\"迁移学习模型（带安全加载）\"\"\"\n",
        "    def __init__(self, pretrained_path):\n",
        "        super().__init__()\n",
        "        self.encoder = PretrainedBioEncoder()\n",
        "        try:\n",
        "            self.encoder.load_state_dict(\n",
        "                torch.load(pretrained_path, map_location='cpu', weights_only=True)\n",
        "            )\n",
        "            print(\"预训练权重加载成功\")\n",
        "        except Exception as e:\n",
        "            print(f\"权重加载失败: {str(e)}\")\n",
        "            self._initialize_weights()\n",
        "        for param in list(self.encoder.parameters())[:4]:\n",
        "            param.requires_grad = False\n",
        "        self.adapter = nn.Sequential(\n",
        "            nn.Linear(192, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(64, 3)\n",
        "        )\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv1d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm1d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.encoder(x)\n",
        "        return self.adapter(features)\n",
        "\n",
        "# ==================== 数据预处理 ====================\n",
        "class ParkinsonDataset(Dataset):\n",
        "    \"\"\"数据加载器（带维度验证）\"\"\"\n",
        "    def __init__(self, df, seq_length=3000):\n",
        "        self.data = df.drop(columns=['timestamp', 'parkinson_label']).values\n",
        "        self.labels = df['parkinson_label'].values\n",
        "        self.seq_length = seq_length\n",
        "        if self.data.shape[1] != 8:\n",
        "            raise ValueError(f\"输入特征数应为8，当前为{self.data.shape[1]}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) // self.seq_length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        start = idx * self.seq_length\n",
        "        end = start + self.seq_length\n",
        "        seq = self.data[start:end].T  # 转置为 [8, 3000]\n",
        "        label = int(self.labels[start:end].mean() > 0.5)\n",
        "        return torch.FloatTensor(seq), torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "# ==================== 训练流程 ====================\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"使用设备: {device}\")\n",
        "\n",
        "    print(\"\\n===== 正在生成数据 =====\")\n",
        "    base_df = generate_base_dataset()\n",
        "    custom_df = generate_custom_data()\n",
        "\n",
        "    print(\"\\n===== 正在处理特征 =====\")\n",
        "    processed_base = kinematic_feature_engineering(base_df)\n",
        "    processed_custom = kinematic_feature_engineering(custom_df)\n",
        "    processed_df = pd.concat([processed_base, processed_custom])\n",
        "    print(\"处理后的特征维度:\", processed_df.shape)\n",
        "    if 'parkinson_label' not in processed_df.columns:\n",
        "        raise KeyError(\"parkinson_label 列在特征工程后丢失！\")\n",
        "    print(\"标签列 'parkinson_label' 已成功保留\")\n",
        "\n",
        "    print(\"\\n===== 正在划分数据集 =====\")\n",
        "    train_dataset = ParkinsonDataset(processed_df.iloc[:24000])\n",
        "    val_dataset = ParkinsonDataset(processed_df.iloc[24000:])\n",
        "    print(f\"训练集样本数: {len(train_dataset)}\")\n",
        "    print(f\"验证集样本数: {len(val_dataset)}\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "    print(\"\\n===== 正在初始化模型 =====\")\n",
        "    model = TransferLearningModel(\n",
        "        \"/content/drive/MyDrive/Parkinson_Project/models/pretrained_bio_model.pth\"\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        filter(lambda p: p.requires_grad, model.parameters()),\n",
        "        lr=1e-4,\n",
        "        weight_decay=1e-5\n",
        "    )\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    print(\"\\n===== 开始训练 =====\")\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(20):\n",
        "        if epoch == 8:\n",
        "            print(\"解冻CNN深层参数\")\n",
        "            for param in model.encoder.cnn.parameters():\n",
        "                param.requires_grad = True\n",
        "        if epoch == 12:\n",
        "            print(\"解冻LSTM参数\")\n",
        "            for param in model.encoder.lstm.parameters():\n",
        "                param.requires_grad = True\n",
        "\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            if torch.isnan(loss):\n",
        "                print(\"警告：损失值为 nan，检查输入数据\")\n",
        "                print(f\"inputs: {inputs}\")\n",
        "                print(f\"outputs: {outputs}\")\n",
        "                break\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_acc = 100 * correct / total\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/20 | 平均损失: {avg_loss:.4f} | 验证准确率: {val_acc:.2f}%\")\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'val_acc': val_acc\n",
        "            }, \"/content/drive/MyDrive/Parkinson_Project/models/best_model.pth\")\n",
        "            print(\"新的最佳模型已保存\")\n",
        "\n",
        "    print(\"\\n===== 生成康复方案测试 =====\")\n",
        "    test_data = {\n",
        "        'timestamp': np.linspace(0, 300, 3000),\n",
        "        'finger_angle': 85 + 10 * np.sin(2 * np.pi * 5 * np.linspace(0, 1, 3000)),\n",
        "        'acceleration': 0.6 * np.exp(-0.005 * np.linspace(0, 300, 3000)),\n",
        "        'emg': 0.7 * np.abs(np.random.randn(3000)),\n",
        "        'parkinson_label': 1\n",
        "    }\n",
        "    plan = predict_rehabilitation_plan(test_data, device)\n",
        "    print(\"\\n生成的帕金森手部训练方案：\")\n",
        "    for key, value in plan.items():\n",
        "        if isinstance(value, list):\n",
        "            print(f\"- {key}:\")\n",
        "            for item in value:\n",
        "                print(f\"  * {item}\")\n",
        "        else:\n",
        "            print(f\"- {key}: {value}\")\n",
        "\n",
        "# ==================== 推理模块 ====================\n",
        "def predict_rehabilitation_plan(input_data, device):\n",
        "    \"\"\"生成详细的康复方案\"\"\"\n",
        "    try:\n",
        "        model = TransferLearningModel(\n",
        "            \"/content/drive/MyDrive/Parkinson_Project/models/pretrained_bio_model.pth\"\n",
        "        ).to(device)\n",
        "\n",
        "        checkpoint_path = \"/content/drive/MyDrive/Parkinson_Project/models/best_model.pth\"\n",
        "        if os.path.exists(checkpoint_path):\n",
        "            checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            print(\"最佳模型权重加载成功\")\n",
        "        else:\n",
        "            print(\"未找到最佳模型权重，使用随机初始化的模型\")\n",
        "\n",
        "        model.eval()\n",
        "        processed_data = kinematic_feature_engineering(pd.DataFrame(input_data))\n",
        "        dataset = ParkinsonDataset(processed_data)\n",
        "        loader = DataLoader(dataset, batch_size=1)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            inputs, labels = next(iter(loader))\n",
        "            print(f\"inputs shape: {inputs.shape}\")\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            print(f\"outputs shape: {outputs.shape}\")\n",
        "            probabilities = torch.softmax(outputs, dim=1).cpu().numpy()\n",
        "            print(f\"probabilities shape: {probabilities.shape}\")\n",
        "            print(f\"probabilities: {probabilities}\")\n",
        "\n",
        "        return {\n",
        "            '基础训练': [\n",
        "                f\"手指伸展训练: {int(probabilities[0][1]*100)}% 强度 (每日3组，每组10次)\",\n",
        "                f\"握力强化训练: {int(probabilities[0][1]*100)}% 强度 (每日2组，每组8次)\"\n",
        "            ],\n",
        "            '高级训练': [\n",
        "                f\"协调性训练: {int(probabilities[0][1]*100)}% 强度 (每日1组，每组5分钟)\",\n",
        "                \"使用压力球进行精细动作练习\"\n",
        "            ],\n",
        "            '注意事项': [\n",
        "                \"训练前后进行10分钟热敷/冷敷\",\n",
        "                \"每个动作间隔休息2分钟\",\n",
        "                \"如出现疼痛或疲劳立即停止\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"生成方案时出错: {str(e)}\")\n",
        "        return {\"error\": \"无法生成训练方案\"}\n",
        "\n",
        "# ==================== 执行主程序 ====================\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkJ8pA__m4Up",
        "outputId": "364ff728-e7f1-40b0-c890-ce6338f3a6c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.1/34.1 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.10.1 which is incompatible.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.0.1 which is incompatible.\n",
            "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.1 which is incompatible.\n",
            "cvxpy 1.6.2 requires scipy>=1.11.0, but you have scipy 1.10.1 which is incompatible.\n",
            "torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.0.1 which is incompatible.\n",
            "jaxlib 0.5.1 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\n",
            "jax 0.5.2 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m使用设备: cpu\n",
            "\n",
            "===== 正在生成数据 =====\n",
            "基准数据集已生成，包含样本数: 30000\n",
            "自定义数据集已生成，包含样本数: 3000\n",
            "\n",
            "===== 正在处理特征 =====\n",
            "处理后的特征维度: (33000, 10)\n",
            "标签列 'parkinson_label' 已成功保留\n",
            "\n",
            "===== 正在划分数据集 =====\n",
            "训练集样本数: 8\n",
            "验证集样本数: 3\n",
            "\n",
            "===== 正在初始化模型 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "权重加载失败: Error(s) in loading state_dict for PretrainedBioEncoder:\n",
            "\tsize mismatch for cnn.0.weight: copying a param with shape torch.Size([32, 9, 5]) from checkpoint, the shape in current model is torch.Size([32, 8, 5]).\n",
            "\tsize mismatch for lstm.weight_ih_l0: copying a param with shape torch.Size([256, 9]) from checkpoint, the shape in current model is torch.Size([256, 8]).\n",
            "\tsize mismatch for lstm.weight_ih_l0_reverse: copying a param with shape torch.Size([256, 9]) from checkpoint, the shape in current model is torch.Size([256, 8]).\n",
            "\n",
            "===== 开始训练 =====\n",
            "Epoch 1/20 | 平均损失: 1.6606 | 验证准确率: 0.00%\n",
            "Epoch 2/20 | 平均损失: 1.3542 | 验证准确率: 0.00%\n",
            "Epoch 3/20 | 平均损失: 1.2315 | 验证准确率: 0.00%\n",
            "Epoch 4/20 | 平均损失: 1.4171 | 验证准确率: 0.00%\n",
            "Epoch 5/20 | 平均损失: 1.3272 | 验证准确率: 0.00%\n",
            "Epoch 6/20 | 平均损失: 1.6265 | 验证准确率: 0.00%\n",
            "Epoch 7/20 | 平均损失: 1.2544 | 验证准确率: 0.00%\n",
            "Epoch 8/20 | 平均损失: 1.1448 | 验证准确率: 0.00%\n",
            "解冻CNN深层参数\n",
            "Epoch 9/20 | 平均损失: 1.2337 | 验证准确率: 0.00%\n",
            "Epoch 10/20 | 平均损失: 0.9555 | 验证准确率: 0.00%\n",
            "Epoch 11/20 | 平均损失: 1.0258 | 验证准确率: 0.00%\n",
            "Epoch 12/20 | 平均损失: 1.1841 | 验证准确率: 0.00%\n",
            "解冻LSTM参数\n",
            "Epoch 13/20 | 平均损失: 1.0601 | 验证准确率: 0.00%\n",
            "Epoch 14/20 | 平均损失: 1.0410 | 验证准确率: 0.00%\n",
            "Epoch 15/20 | 平均损失: 0.8827 | 验证准确率: 33.33%\n",
            "新的最佳模型已保存\n",
            "Epoch 16/20 | 平均损失: 0.9195 | 验证准确率: 66.67%\n",
            "新的最佳模型已保存\n",
            "Epoch 17/20 | 平均损失: 0.9154 | 验证准确率: 66.67%\n",
            "Epoch 18/20 | 平均损失: 0.8373 | 验证准确率: 66.67%\n",
            "Epoch 19/20 | 平均损失: 0.6795 | 验证准确率: 66.67%\n",
            "Epoch 20/20 | 平均损失: 0.7244 | 验证准确率: 66.67%\n",
            "\n",
            "===== 生成康复方案测试 =====\n",
            "权重加载失败: Error(s) in loading state_dict for PretrainedBioEncoder:\n",
            "\tsize mismatch for cnn.0.weight: copying a param with shape torch.Size([32, 9, 5]) from checkpoint, the shape in current model is torch.Size([32, 8, 5]).\n",
            "\tsize mismatch for lstm.weight_ih_l0: copying a param with shape torch.Size([256, 9]) from checkpoint, the shape in current model is torch.Size([256, 8]).\n",
            "\tsize mismatch for lstm.weight_ih_l0_reverse: copying a param with shape torch.Size([256, 9]) from checkpoint, the shape in current model is torch.Size([256, 8]).\n",
            "最佳模型权重加载成功\n",
            "inputs shape: torch.Size([1, 8, 3000])\n",
            "outputs shape: torch.Size([1, 3])\n",
            "probabilities shape: (1, 3)\n",
            "probabilities: [[0.36020717 0.26979053 0.37000227]]\n",
            "\n",
            "生成的帕金森手部训练方案：\n",
            "- 基础训练:\n",
            "  * 手指伸展训练: 26% 强度 (每日3组，每组10次)\n",
            "  * 握力强化训练: 26% 强度 (每日2组，每组8次)\n",
            "- 高级训练:\n",
            "  * 协调性训练: 26% 强度 (每日1组，每组5分钟)\n",
            "  * 使用压力球进行精细动作练习\n",
            "- 注意事项:\n",
            "  * 训练前后进行10分钟热敷/冷敷\n",
            "  * 每个动作间隔休息2分钟\n",
            "  * 如出现疼痛或疲劳立即停止\n"
          ]
        }
      ]
    }
  ]
}