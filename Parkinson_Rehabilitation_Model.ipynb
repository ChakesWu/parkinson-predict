{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChakesWu/parkinson-predict/blob/main/Parkinson_Rehabilitation_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkJ8pA__m4Up",
        "outputId": "2da11a3a-124d-4590-f818-e5f3ed91346b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Parkinson Rehabilitation System.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at:\n",
        "    https://colab.research.google.com/drive/your-drive-link\n",
        "\"\"\"\n",
        "\n",
        "# ==================== 环境配置 ====================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# 创建项目目录结构\n",
        "!mkdir -p \"/content/drive/MyDrive/Parkinson_Project/{data,models,results}\"\n",
        "\n",
        "# 安装依赖库（修复版本冲突）\n",
        "!pip install torch==2.0.1 scipy==1.10.1 neurokit2==0.2.4 matplotlib==3.7.1 -q\n",
        "\n",
        "# ==================== 数据生成模块 ====================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import signal\n",
        "import os\n",
        "import time\n",
        "\n",
        "def generate_base_dataset(samples=30000):\n",
        "    \"\"\"生成基准临床数据集（100Hz采样，5分钟数据）\"\"\"\n",
        "    np.random.seed(42)\n",
        "    fs = 100  # 采样频率\n",
        "    t = np.linspace(0, 300, samples)\n",
        "    tremor_freq = 4 + np.random.normal(0, 0.5)\n",
        "    finger_angle = 90 + 10 * signal.sawtooth(2 * np.pi * tremor_freq * t)\n",
        "    finger_angle += np.random.normal(0, 2, samples)\n",
        "    acceleration = 0.8 * np.sin(2 * np.pi * 0.3 * t) * np.exp(-0.005*t)\n",
        "    acceleration += 0.1 * np.random.randn(samples)\n",
        "    emg_bursts = np.zeros(samples)\n",
        "    for i in range(0, samples, 2000):\n",
        "        burst = 0.5 * np.abs(signal.hilbert(np.random.randn(500)))\n",
        "        emg_bursts[i:i+500] = burst\n",
        "    emg = 0.4 * np.abs(signal.hilbert(np.random.randn(samples))) + emg_bursts\n",
        "    labels = np.where(\n",
        "        (np.std(finger_angle) > 8) &\n",
        "        (np.mean(emg) > 0.45) &\n",
        "        (np.max(acceleration) < 1.2),\n",
        "        1, 0\n",
        "    )\n",
        "    df = pd.DataFrame({\n",
        "        'timestamp': t,\n",
        "        'finger_angle': finger_angle,\n",
        "        'acceleration': acceleration,\n",
        "        'emg': emg,\n",
        "        'parkinson_label': labels\n",
        "    })\n",
        "    df.to_csv(\"/content/drive/MyDrive/Parkinson_Project/data/base_data.csv\", index=False)\n",
        "    print(\"基准数据集已生成，包含样本数:\", len(df))\n",
        "    return df\n",
        "\n",
        "def generate_custom_data(samples=3000):\n",
        "    \"\"\"生成用户自定义数据（50Hz采样，模拟设备采集）\"\"\"\n",
        "    np.random.seed(int(time.time()))\n",
        "    t = np.linspace(0, 300, samples)\n",
        "    finger_angle = 85 + 12 * signal.sawtooth(2 * np.pi * 5.5 * t)\n",
        "    finger_angle += np.random.normal(0, 3, samples)\n",
        "    acceleration = 0.6 * np.sin(2 * np.pi * 0.25 * t) * np.exp(-0.004*t)\n",
        "    acceleration += 0.15 * np.random.randn(samples)\n",
        "    emg = 0.5 * np.abs(signal.hilbert(np.random.randn(samples)))\n",
        "    spike_indices = np.random.choice(samples, 50, replace=False)\n",
        "    emg[spike_indices] += 0.8\n",
        "    df = pd.DataFrame({\n",
        "        'timestamp': t,\n",
        "        'finger_angle': finger_angle,\n",
        "        'acceleration': acceleration,\n",
        "        'emg': emg,\n",
        "        'parkinson_label': 1\n",
        "    })\n",
        "    df.to_csv(\"/content/drive/MyDrive/Parkinson_Project/data/custom_data.csv\", index=False)\n",
        "    print(\"自定义数据集已生成，包含样本数:\", len(df))\n",
        "    return df\n",
        "\n",
        "# ==================== 特征工程模块 ====================\n",
        "def kinematic_feature_engineering(df):\n",
        "    \"\"\"运动学特征增强（最终生成9个特征，并保留标签列）\"\"\"\n",
        "    df['angle_velocity'] = np.gradient(df['finger_angle'], df['timestamp'])\n",
        "    df['angle_acceleration'] = np.gradient(df['angle_velocity'], df['timestamp'])\n",
        "    freqs, psd = signal.welch(df['emg'], fs=100, nperseg=512)\n",
        "    df['emg_peak_freq'] = freqs[np.argmax(psd)]\n",
        "    df['emg_psd_ratio'] = psd[(freqs > 10) & (freqs < 35)].sum() / psd.sum()\n",
        "    features = [\n",
        "        'finger_angle', 'acceleration', 'emg',\n",
        "        'angle_velocity', 'angle_acceleration',\n",
        "        'emg_peak_freq', 'emg_psd_ratio'\n",
        "    ]\n",
        "    for feat in features:\n",
        "        df[feat] = df[feat].replace([np.inf, -np.inf], np.nan)\n",
        "        df[feat] = df[feat].fillna(df[feat].mean())\n",
        "    df[features] = (df[features] - df[features].mean()) / df[features].std()\n",
        "    df[features] = df[features].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "    df['rolling_angle_var'] = df['finger_angle'].rolling(window=100, center=True).var().fillna(0)\n",
        "    final_features = [\n",
        "        'finger_angle', 'acceleration', 'emg',\n",
        "        'angle_velocity', 'angle_acceleration',\n",
        "        'emg_peak_freq', 'emg_psd_ratio',\n",
        "        'rolling_angle_var', 'timestamp',\n",
        "        'parkinson_label'\n",
        "    ]\n",
        "    return df[final_features]\n",
        "\n",
        "# ==================== 模型架构 ====================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class PretrainedBioEncoder(nn.Module):\n",
        "    \"\"\"8通道输入版本（对应8个特征）\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(8, 32, 5, padding=2),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Conv1d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1)\n",
        "        )\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=8,\n",
        "            hidden_size=64,\n",
        "            bidirectional=True,\n",
        "            num_layers=2,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # CNN 处理 [batch_size, channels, time]\n",
        "        cnn_feat = self.cnn(x).squeeze(-1)\n",
        "        # LSTM 处理 [batch_size, time, input_size]\n",
        "        lstm_input = x.permute(0, 2, 1)  # 从 [batch_size, 8, 3000] 转为 [batch_size, 3000, 8]\n",
        "        lstm_out, _ = self.lstm(lstm_input)\n",
        "        lstm_feat = lstm_out[:, -1, :]\n",
        "        return torch.cat([cnn_feat, lstm_feat], dim=1)\n",
        "\n",
        "class TransferLearningModel(nn.Module):\n",
        "    \"\"\"迁移学习模型（带安全加载）\"\"\"\n",
        "    def __init__(self, pretrained_path):\n",
        "        super().__init__()\n",
        "        self.encoder = PretrainedBioEncoder()\n",
        "        try:\n",
        "            self.encoder.load_state_dict(\n",
        "                torch.load(pretrained_path, map_location='cpu', weights_only=True)\n",
        "            )\n",
        "            print(\"预训练权重加载成功\")\n",
        "        except Exception as e:\n",
        "            print(f\"权重加载失败: {str(e)}\")\n",
        "            self._initialize_weights()\n",
        "        for param in list(self.encoder.parameters())[:4]:\n",
        "            param.requires_grad = False\n",
        "        self.adapter = nn.Sequential(\n",
        "            nn.Linear(192, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(64, 3)\n",
        "        )\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv1d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm1d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.encoder(x)\n",
        "        return self.adapter(features)\n",
        "\n",
        "# ==================== 数据预处理 ====================\n",
        "class ParkinsonDataset(Dataset):\n",
        "    \"\"\"数据加载器（带维度验证）\"\"\"\n",
        "    def __init__(self, df, seq_length=3000):\n",
        "        self.data = df.drop(columns=['timestamp', 'parkinson_label']).values\n",
        "        self.labels = df['parkinson_label'].values\n",
        "        self.seq_length = seq_length\n",
        "        if self.data.shape[1] != 8:\n",
        "            raise ValueError(f\"输入特征数应为8，当前为{self.data.shape[1]}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) // self.seq_length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        start = idx * self.seq_length\n",
        "        end = start + self.seq_length\n",
        "        seq = self.data[start:end].T  # 转置为 [8, 3000]\n",
        "        label = int(self.labels[start:end].mean() > 0.5)\n",
        "        return torch.FloatTensor(seq), torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "# ==================== 训练流程 ====================\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"使用设备: {device}\")\n",
        "\n",
        "    print(\"\\n===== 正在生成数据 =====\")\n",
        "    base_df = generate_base_dataset()\n",
        "    custom_df = generate_custom_data()\n",
        "\n",
        "    print(\"\\n===== 正在处理特征 =====\")\n",
        "    processed_base = kinematic_feature_engineering(base_df)\n",
        "    processed_custom = kinematic_feature_engineering(custom_df)\n",
        "    processed_df = pd.concat([processed_base, processed_custom])\n",
        "    print(\"处理后的特征维度:\", processed_df.shape)\n",
        "    if 'parkinson_label' not in processed_df.columns:\n",
        "        raise KeyError(\"parkinson_label 列在特征工程后丢失！\")\n",
        "    print(\"标签列 'parkinson_label' 已成功保留\")\n",
        "\n",
        "    print(\"\\n===== 正在划分数据集 =====\")\n",
        "    train_dataset = ParkinsonDataset(processed_df.iloc[:24000])\n",
        "    val_dataset = ParkinsonDataset(processed_df.iloc[24000:])\n",
        "    print(f\"训练集样本数: {len(train_dataset)}\")\n",
        "    print(f\"验证集样本数: {len(val_dataset)}\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "    print(\"\\n===== 正在初始化模型 =====\")\n",
        "    model = TransferLearningModel(\n",
        "        \"/content/drive/MyDrive/Parkinson_Project/models/pretrained_bio_model.pth\"\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        filter(lambda p: p.requires_grad, model.parameters()),\n",
        "        lr=1e-4,\n",
        "        weight_decay=1e-5\n",
        "    )\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    print(\"\\n===== 开始训练 =====\")\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(20):\n",
        "        if epoch == 8:\n",
        "            print(\"解冻CNN深层参数\")\n",
        "            for param in model.encoder.cnn.parameters():\n",
        "                param.requires_grad = True\n",
        "        if epoch == 12:\n",
        "            print(\"解冻LSTM参数\")\n",
        "            for param in model.encoder.lstm.parameters():\n",
        "                param.requires_grad = True\n",
        "\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            if torch.isnan(loss):\n",
        "                print(\"警告：损失值为 nan，检查输入数据\")\n",
        "                print(f\"inputs: {inputs}\")\n",
        "                print(f\"outputs: {outputs}\")\n",
        "                break\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_acc = 100 * correct / total\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/20 | 平均损失: {avg_loss:.4f} | 验证准确率: {val_acc:.2f}%\")\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'val_acc': val_acc\n",
        "            }, \"/content/drive/MyDrive/Parkinson_Project/models/best_model.pth\")\n",
        "            print(\"新的最佳模型已保存\")\n",
        "\n",
        "    print(\"\\n===== 生成康复方案测试 =====\")\n",
        "    test_data = {\n",
        "        'timestamp': np.linspace(0, 300, 3000),\n",
        "        'finger_angle': 85 + 10 * np.sin(2 * np.pi * 5 * np.linspace(0, 1, 3000)),\n",
        "        'acceleration': 0.6 * np.exp(-0.005 * np.linspace(0, 300, 3000)),\n",
        "        'emg': 0.7 * np.abs(np.random.randn(3000)),\n",
        "        'parkinson_label': 1\n",
        "    }\n",
        "    plan = predict_rehabilitation_plan(test_data, device)\n",
        "    print(\"\\n生成的帕金森手部训练方案：\")\n",
        "    for key, value in plan.items():\n",
        "        if isinstance(value, list):\n",
        "            print(f\"- {key}:\")\n",
        "            for item in value:\n",
        "                print(f\"  * {item}\")\n",
        "        else:\n",
        "            print(f\"- {key}: {value}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpT7UFi3f481",
        "outputId": "a53b198f-77fe-4eeb-d96d-ccabcd79476a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "使用设备: cpu\n",
            "\n",
            "===== 正在生成数据 =====\n",
            "基准数据集已生成，包含样本数: 30000\n",
            "自定义数据集已生成，包含样本数: 3000\n",
            "\n",
            "===== 正在处理特征 =====\n",
            "处理后的特征维度: (33000, 10)\n",
            "标签列 'parkinson_label' 已成功保留\n",
            "\n",
            "===== 正在划分数据集 =====\n",
            "训练集样本数: 8\n",
            "验证集样本数: 3\n",
            "\n",
            "===== 正在初始化模型 =====\n",
            "权重加载失败: Error(s) in loading state_dict for PretrainedBioEncoder:\n",
            "\tsize mismatch for cnn.0.weight: copying a param with shape torch.Size([32, 9, 5]) from checkpoint, the shape in current model is torch.Size([32, 8, 5]).\n",
            "\tsize mismatch for lstm.weight_ih_l0: copying a param with shape torch.Size([256, 9]) from checkpoint, the shape in current model is torch.Size([256, 8]).\n",
            "\tsize mismatch for lstm.weight_ih_l0_reverse: copying a param with shape torch.Size([256, 9]) from checkpoint, the shape in current model is torch.Size([256, 8]).\n",
            "\n",
            "===== 开始训练 =====\n",
            "Epoch 1/20 | 平均损失: 1.6539 | 验证准确率: 33.33%\n",
            "新的最佳模型已保存\n",
            "Epoch 2/20 | 平均损失: 1.5617 | 验证准确率: 33.33%\n",
            "Epoch 3/20 | 平均损失: 1.5903 | 验证准确率: 33.33%\n",
            "Epoch 4/20 | 平均损失: 1.4266 | 验证准确率: 33.33%\n",
            "Epoch 5/20 | 平均损失: 1.4348 | 验证准确率: 33.33%\n",
            "Epoch 6/20 | 平均损失: 1.3762 | 验证准确率: 33.33%\n",
            "Epoch 7/20 | 平均损失: 1.4291 | 验证准确率: 33.33%\n",
            "Epoch 8/20 | 平均损失: 1.2522 | 验证准确率: 33.33%\n",
            "解冻CNN深层参数\n",
            "Epoch 9/20 | 平均损失: 1.2914 | 验证准确率: 33.33%\n",
            "Epoch 10/20 | 平均损失: 1.2570 | 验证准确率: 33.33%\n",
            "Epoch 11/20 | 平均损失: 1.2537 | 验证准确率: 33.33%\n",
            "Epoch 12/20 | 平均损失: 1.1858 | 验证准确率: 33.33%\n",
            "解冻LSTM参数\n",
            "Epoch 13/20 | 平均损失: 1.1386 | 验证准确率: 33.33%\n",
            "Epoch 14/20 | 平均损失: 1.0923 | 验证准确率: 33.33%\n",
            "Epoch 15/20 | 平均损失: 1.0764 | 验证准确率: 33.33%\n",
            "Epoch 16/20 | 平均损失: 1.0948 | 验证准确率: 33.33%\n",
            "Epoch 17/20 | 平均损失: 1.1121 | 验证准确率: 33.33%\n",
            "Epoch 18/20 | 平均损失: 0.8353 | 验证准确率: 33.33%\n",
            "Epoch 19/20 | 平均损失: 0.9426 | 验证准确率: 33.33%\n",
            "Epoch 20/20 | 平均损失: 0.9712 | 验证准确率: 33.33%\n",
            "\n",
            "===== 生成康复方案测试 =====\n",
            "权重加载失败: Error(s) in loading state_dict for PretrainedBioEncoder:\n",
            "\tsize mismatch for cnn.0.weight: copying a param with shape torch.Size([32, 9, 5]) from checkpoint, the shape in current model is torch.Size([32, 8, 5]).\n",
            "\tsize mismatch for lstm.weight_ih_l0: copying a param with shape torch.Size([256, 9]) from checkpoint, the shape in current model is torch.Size([256, 8]).\n",
            "\tsize mismatch for lstm.weight_ih_l0_reverse: copying a param with shape torch.Size([256, 9]) from checkpoint, the shape in current model is torch.Size([256, 8]).\n",
            "最佳模型权重加载成功\n",
            "inputs shape: torch.Size([1, 8, 3000])\n",
            "outputs shape: torch.Size([1, 3])\n",
            "probabilities shape: (1, 3)\n",
            "probabilities: [[0.29560792 0.44100624 0.2633858 ]]\n",
            "\n",
            "生成的帕金森手部训练方案：\n",
            "- 基础训练:\n",
            "  * 手指伸展训练: 44% 强度 (每日3组，每组10次)\n",
            "  * 握力强化训练: 44% 强度 (每日2组，每组8次)\n",
            "- 高级训练:\n",
            "  * 协调性训练: 44% 强度 (每日1组，每组5分钟)\n",
            "  * 使用压力球进行精细动作练习\n",
            "- 注意事项:\n",
            "  * 训练前后进行10分钟热敷/冷敷\n",
            "  * 每个动作间隔休息2分钟\n",
            "  * 如出现疼痛或疲劳立即停止\n"
          ]
        }
      ],
      "source": [
        "# ==================== 推理模块 ====================\n",
        "def predict_rehabilitation_plan(input_data, device):\n",
        "    \"\"\"生成详细的康复方案\"\"\"\n",
        "    try:\n",
        "        model = TransferLearningModel(\n",
        "            \"/content/drive/MyDrive/Parkinson_Project/models/pretrained_bio_model.pth\"\n",
        "        ).to(device)\n",
        "\n",
        "        checkpoint_path = \"/content/drive/MyDrive/Parkinson_Project/models/best_model.pth\"\n",
        "        if os.path.exists(checkpoint_path):\n",
        "            checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            print(\"最佳模型权重加载成功\")\n",
        "        else:\n",
        "            print(\"未找到最佳模型权重，使用随机初始化的模型\")\n",
        "\n",
        "        model.eval()\n",
        "        processed_data = kinematic_feature_engineering(pd.DataFrame(input_data))\n",
        "        dataset = ParkinsonDataset(processed_data)\n",
        "        loader = DataLoader(dataset, batch_size=1)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            inputs, labels = next(iter(loader))\n",
        "            print(f\"inputs shape: {inputs.shape}\")\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            print(f\"outputs shape: {outputs.shape}\")\n",
        "            probabilities = torch.softmax(outputs, dim=1).cpu().numpy()\n",
        "            print(f\"probabilities shape: {probabilities.shape}\")\n",
        "            print(f\"probabilities: {probabilities}\")\n",
        "\n",
        "        return {\n",
        "            '基础训练': [\n",
        "                f\"手指伸展训练: {int(probabilities[0][1]*100)}% 强度 (每日3组，每组10次)\",\n",
        "                f\"握力强化训练: {int(probabilities[0][1]*100)}% 强度 (每日2组，每组8次)\"\n",
        "            ],\n",
        "            '高级训练': [\n",
        "                f\"协调性训练: {int(probabilities[0][1]*100)}% 强度 (每日1组，每组5分钟)\",\n",
        "                \"使用压力球进行精细动作练习\"\n",
        "            ],\n",
        "            '注意事项': [\n",
        "                \"训练前后进行10分钟热敷/冷敷\",\n",
        "                \"每个动作间隔休息2分钟\",\n",
        "                \"如出现疼痛或疲劳立即停止\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"生成方案时出错: {str(e)}\")\n",
        "        return {\"error\": \"无法生成训练方案\"}\n",
        "\n",
        "# ==================== 执行主程序 ====================\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IyYVcotpjPe",
        "outputId": "37935c73-8fcc-4b50-eeda-216bbab3d36a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "使用設備: cpu\n",
            "\n",
            "===== 正在生成數據 =====\n",
            "基準數據集已生成，包含樣本數: 30000\n",
            "\n",
            "===== 正在加載 CSV 數據 =====\n",
            "CSV 數據集已加載，包含樣本數: 30000\n",
            "列名: ['timestamp', 'finger_angle', 'acceleration', 'emg', 'parkinson_label']\n",
            "\n",
            "===== 正在合併數據 =====\n",
            "合併後的數據集總樣本數: 60000\n",
            "標籤分佈:\n",
            " parkinson_label\n",
            "0    60000\n",
            "Name: count, dtype: int64\n",
            "\n",
            "===== 正在處理特徵 =====\n",
            "特徵工程後數據檢查:\n",
            " finger_angle          0\n",
            "acceleration          0\n",
            "emg                   0\n",
            "angle_velocity        0\n",
            "angle_acceleration    0\n",
            "emg_peak_freq         0\n",
            "emg_psd_ratio         0\n",
            "rolling_angle_var     0\n",
            "timestamp             0\n",
            "parkinson_label       0\n",
            "dtype: int64\n",
            "處理後的特徵維度: (60000, 10)\n",
            "\n",
            "===== 正在劃分數據集 =====\n",
            "訓練集樣本數: 16\n",
            "驗證集樣本數: 4\n",
            "\n",
            "===== 正在初始化模型 =====\n",
            "\n",
            "===== 開始訓練 =====\n",
            "Epoch 1/20 | 平均損失: 1.1320 | 驗證準確率: 0.00%\n",
            "Epoch 2/20 | 平均損失: 1.0752 | 驗證準確率: 25.00%\n",
            "新的最佳模型已保存\n",
            "Epoch 3/20 | 平均損失: 1.0073 | 驗證準確率: 75.00%\n",
            "新的最佳模型已保存\n",
            "Epoch 4/20 | 平均損失: 0.8504 | 驗證準確率: 100.00%\n",
            "新的最佳模型已保存\n",
            "Epoch 5/20 | 平均損失: 0.9070 | 驗證準確率: 100.00%\n",
            "Epoch 6/20 | 平均損失: 0.9128 | 驗證準確率: 100.00%\n",
            "Epoch 7/20 | 平均損失: 0.9379 | 驗證準確率: 100.00%\n",
            "Epoch 8/20 | 平均損失: 0.7355 | 驗證準確率: 100.00%\n",
            "Epoch 9/20 | 平均損失: 0.8128 | 驗證準確率: 100.00%\n",
            "Epoch 10/20 | 平均損失: 0.8005 | 驗證準確率: 100.00%\n",
            "Epoch 11/20 | 平均損失: 0.7325 | 驗證準確率: 100.00%\n",
            "Epoch 12/20 | 平均損失: 0.8081 | 驗證準確率: 100.00%\n",
            "Epoch 13/20 | 平均損失: 0.6503 | 驗證準確率: 100.00%\n",
            "Epoch 14/20 | 平均損失: 0.6354 | 驗證準確率: 100.00%\n",
            "Epoch 15/20 | 平均損失: 0.6017 | 驗證準確率: 100.00%\n",
            "Epoch 16/20 | 平均損失: 0.5974 | 驗證準確率: 100.00%\n",
            "Epoch 17/20 | 平均損失: 0.4503 | 驗證準確率: 100.00%\n",
            "Epoch 18/20 | 平均損失: 0.6244 | 驗證準確率: 100.00%\n",
            "Epoch 19/20 | 平均損失: 0.4551 | 驗證準確率: 100.00%\n",
            "Epoch 20/20 | 平均損失: 0.5872 | 驗證準確率: 100.00%\n",
            "\n",
            "===== 生成康復方案測試 =====\n",
            "最佳模型權重加載成功\n",
            "特徵工程後數據檢查:\n",
            " finger_angle          0\n",
            "acceleration          0\n",
            "emg                   0\n",
            "angle_velocity        0\n",
            "angle_acceleration    0\n",
            "emg_peak_freq         0\n",
            "emg_psd_ratio         0\n",
            "rolling_angle_var     0\n",
            "timestamp             0\n",
            "parkinson_label       0\n",
            "dtype: int64\n",
            "\n",
            "生成的帕金森手部訓練方案：\n",
            "- 基礎訓練:\n",
            "  * 手指伸展訓練: 26% 強度 (每日3組，每組10次)\n",
            "  * 握力強化訓練: 26% 強度 (每日2組，每組8次)\n",
            "- 高級訓練:\n",
            "  * 協調性訓練: 26% 強度 (每日1組，每組5分鐘)\n",
            "  * 使用壓力球進行精細動作練習\n",
            "- 注意事項:\n",
            "  * 訓練前後進行10分鐘熱敷/冷敷\n",
            "  * 每個動作間隔休息2分鐘\n",
            "  * 如出現疼痛或疲勞立即停止\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Parkinson Rehabilitation System with Combined Data\"\"\"\n",
        "\n",
        "# ==================== 環境配置 ====================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# 創建項目目錄結構\n",
        "!mkdir -p \"/content/drive/MyDrive/Parkinson_Project/{data,models,results}\"\n",
        "\n",
        "# 安裝依賴庫\n",
        "!pip install torch==2.0.1 scipy==1.10.1 neurokit2==0.2.4 matplotlib==3.7.1 -q\n",
        "\n",
        "# ==================== 數據生成與加載模塊 ====================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import signal\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "def generate_base_dataset(samples=30000):\n",
        "    \"\"\"生成基準臨床數據集（100Hz採樣，5分鐘數據）\"\"\"\n",
        "    np.random.seed(42)\n",
        "    fs = 100\n",
        "    t = np.linspace(0, 300, samples)\n",
        "    tremor_freq = 4 + np.random.normal(0, 0.5)\n",
        "    finger_angle = 90 + 10 * signal.sawtooth(2 * np.pi * tremor_freq * t)\n",
        "    finger_angle += np.random.normal(0, 2, samples)\n",
        "    acceleration = 0.8 * np.sin(2 * np.pi * 0.3 * t) * np.exp(-0.005*t)\n",
        "    acceleration += 0.1 * np.random.randn(samples)\n",
        "    emg_bursts = np.zeros(samples)\n",
        "    for i in range(0, samples, 2000):\n",
        "        burst = 0.5 * np.abs(signal.hilbert(np.random.randn(500)))\n",
        "        emg_bursts[i:i+500] = burst\n",
        "    emg = 0.4 * np.abs(signal.hilbert(np.random.randn(samples))) + emg_bursts\n",
        "    labels = np.where(\n",
        "        (np.std(finger_angle) > 8) &\n",
        "        (np.mean(emg) > 0.45) &\n",
        "        (np.max(acceleration) < 1.2),\n",
        "        1, 0\n",
        "    )\n",
        "    df = pd.DataFrame({\n",
        "        'timestamp': t,\n",
        "        'finger_angle': finger_angle,\n",
        "        'acceleration': acceleration,\n",
        "        'emg': emg,\n",
        "        'parkinson_label': labels\n",
        "    })\n",
        "    df.to_csv(\"/content/drive/MyDrive/Parkinson_Project/data/generated_base_data.csv\", index=False)\n",
        "    print(\"基準數據集已生成，包含樣本數:\", len(df))\n",
        "    return df\n",
        "\n",
        "def load_csv_dataset(file_path):\n",
        "    \"\"\"加載 CSV 數據集\"\"\"\n",
        "    df = pd.read_csv(file_path)\n",
        "    print(\"CSV 數據集已加載，包含樣本數:\", len(df))\n",
        "    print(\"列名:\", df.columns.tolist())\n",
        "    return df\n",
        "\n",
        "def combine_datasets(generated_df, csv_df):\n",
        "    \"\"\"合併生成數據和 CSV 數據\"\"\"\n",
        "    combined_df = pd.concat([generated_df, csv_df], ignore_index=True)\n",
        "    print(\"合併後的數據集總樣本數:\", len(combined_df))\n",
        "    print(\"標籤分佈:\\n\", combined_df['parkinson_label'].value_counts())\n",
        "    return combined_df\n",
        "\n",
        "# ==================== 特徵工程模塊 ====================\n",
        "def kinematic_feature_engineering(df):\n",
        "    \"\"\"運動學特徵增強\"\"\"\n",
        "    df['angle_velocity'] = np.gradient(df['finger_angle'], df['timestamp'])\n",
        "    df['angle_acceleration'] = np.gradient(df['angle_velocity'], df['timestamp'])\n",
        "    freqs, psd = signal.welch(df['emg'], fs=100, nperseg=512)\n",
        "    df['emg_peak_freq'] = freqs[np.argmax(psd)]\n",
        "    df['emg_psd_ratio'] = psd[(freqs > 10) & (freqs < 35)].sum() / psd.sum()\n",
        "    features = [\n",
        "        'finger_angle', 'acceleration', 'emg',\n",
        "        'angle_velocity', 'angle_acceleration',\n",
        "        'emg_peak_freq', 'emg_psd_ratio'\n",
        "    ]\n",
        "    for feat in features:\n",
        "        df[feat] = df[feat].replace([np.inf, -np.inf], np.nan).fillna(df[feat].mean())\n",
        "    df[features] = (df[features] - df[features].mean()) / df[features].std()\n",
        "    df[features] = df[features].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "    df['rolling_angle_var'] = df['finger_angle'].rolling(window=100, center=True).var().fillna(0)\n",
        "    final_features = [\n",
        "        'finger_angle', 'acceleration', 'emg',\n",
        "        'angle_velocity', 'angle_acceleration',\n",
        "        'emg_peak_freq', 'emg_psd_ratio',\n",
        "        'rolling_angle_var', 'timestamp',\n",
        "        'parkinson_label'\n",
        "    ]\n",
        "    print(\"特徵工程後數據檢查:\\n\", df[final_features].isna().sum())\n",
        "    return df[final_features]\n",
        "\n",
        "# ==================== 模型架構 ====================\n",
        "class PretrainedBioEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(8, 32, 5, padding=2),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Conv1d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1)\n",
        "        )\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=8,\n",
        "            hidden_size=64,\n",
        "            bidirectional=True,\n",
        "            num_layers=2,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        cnn_feat = self.cnn(x).squeeze(-1)\n",
        "        lstm_input = x.permute(0, 2, 1)\n",
        "        lstm_out, _ = self.lstm(lstm_input)\n",
        "        lstm_feat = lstm_out[:, -1, :]\n",
        "        return torch.cat([cnn_feat, lstm_feat], dim=1)\n",
        "\n",
        "class TransferLearningModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = PretrainedBioEncoder()\n",
        "        self._initialize_weights()\n",
        "        for param in list(self.encoder.parameters())[:4]:\n",
        "            param.requires_grad = False\n",
        "        self.adapter = nn.Sequential(\n",
        "            nn.Linear(192, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(64, 3)\n",
        "        )\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv1d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm1d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.encoder(x)\n",
        "        return self.adapter(features)\n",
        "\n",
        "# ==================== 數據預處理 ====================\n",
        "class ParkinsonDataset(Dataset):\n",
        "    def __init__(self, df, seq_length=3000):\n",
        "        self.data = df.drop(columns=['timestamp', 'parkinson_label']).values\n",
        "        self.labels = df['parkinson_label'].values\n",
        "        self.seq_length = seq_length\n",
        "        if self.data.shape[1] != 8:\n",
        "            raise ValueError(f\"輸入特徵數應為8，當前為{self.data.shape[1]}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) // self.seq_length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        start = idx * self.seq_length\n",
        "        end = start + self.seq_length  # 修正此處\n",
        "        seq = self.data[start:end].T\n",
        "        label = int(self.labels[start:end].mean() > 0.5)\n",
        "        return torch.FloatTensor(seq), torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "# ==================== 訓練流程 ====================\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"使用設備: {device}\")\n",
        "\n",
        "    print(\"\\n===== 正在生成數據 =====\")\n",
        "    generated_df = generate_base_dataset()\n",
        "\n",
        "    print(\"\\n===== 正在加載 CSV 數據 =====\")\n",
        "    csv_file_path = \"/content/drive/MyDrive/Parkinson_Project/data/base_data.csv\"\n",
        "    if not os.path.exists(csv_file_path):\n",
        "        !gdown \"https://drive.google.com/uc?id=1XWg7weCeZHIvUSVGX3TP_U23b5c70mAB\" -O {csv_file_path}\n",
        "    csv_df = load_csv_dataset(csv_file_path)\n",
        "\n",
        "    print(\"\\n===== 正在合併數據 =====\")\n",
        "    combined_df = combine_datasets(generated_df, csv_df)\n",
        "\n",
        "    print(\"\\n===== 正在處理特徵 =====\")\n",
        "    processed_df = kinematic_feature_engineering(combined_df)\n",
        "    print(\"處理後的特徵維度:\", processed_df.shape)\n",
        "\n",
        "    print(\"\\n===== 正在劃分數據集 =====\")\n",
        "    train_size = int(0.8 * len(processed_df))\n",
        "    train_dataset = ParkinsonDataset(processed_df.iloc[:train_size])\n",
        "    val_dataset = ParkinsonDataset(processed_df.iloc[train_size:])\n",
        "    print(f\"訓練集樣本數: {len(train_dataset)}\")\n",
        "    print(f\"驗證集樣本數: {len(val_dataset)}\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "    print(\"\\n===== 正在初始化模型 =====\")\n",
        "    model = TransferLearningModel().to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        filter(lambda p: p.requires_grad, model.parameters()),\n",
        "        lr=1e-4,\n",
        "        weight_decay=1e-5\n",
        "    )\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    print(\"\\n===== 開始訓練 =====\")\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(20):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            if torch.isnan(loss):\n",
        "                print(\"警告：損失值為 nan，檢查輸入數據\")\n",
        "                print(\"Inputs:\", inputs)\n",
        "                print(\"Outputs:\", outputs)\n",
        "                break\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_acc = 100 * correct / total\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/20 | 平均損失: {avg_loss:.4f} | 驗證準確率: {val_acc:.2f}%\")\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'val_acc': val_acc\n",
        "            }, \"/content/drive/MyDrive/Parkinson_Project/models/best_model.pth\")\n",
        "            print(\"新的最佳模型已保存\")\n",
        "\n",
        "    print(\"\\n===== 生成康復方案測試 =====\")\n",
        "    test_data = {\n",
        "        'timestamp': np.linspace(0, 300, 3000),\n",
        "        'finger_angle': 85 + 10 * np.sin(2 * np.pi * 5 * np.linspace(0, 1, 3000)),\n",
        "        'acceleration': 0.6 * np.exp(-0.005 * np.linspace(0, 300, 3000)),\n",
        "        'emg': 0.7 * np.abs(np.random.randn(3000)),\n",
        "        'parkinson_label': 1\n",
        "    }\n",
        "    plan = predict_rehabilitation_plan(test_data, device)\n",
        "    print(\"\\n生成的帕金森手部訓練方案：\")\n",
        "    for key, value in plan.items():\n",
        "        if isinstance(value, list):\n",
        "            print(f\"- {key}:\")\n",
        "            for item in value:\n",
        "                print(f\"  * {item}\")\n",
        "        else:\n",
        "            print(f\"- {key}: {value}\")\n",
        "\n",
        "# ==================== 推理模塊 ====================\n",
        "def predict_rehabilitation_plan(input_data, device):\n",
        "    \"\"\"生成詳細的康復方案\"\"\"\n",
        "    try:\n",
        "        model = TransferLearningModel().to(device)\n",
        "        checkpoint_path = \"/content/drive/MyDrive/Parkinson_Project/models/best_model.pth\"\n",
        "        if os.path.exists(checkpoint_path):\n",
        "            checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            print(\"最佳模型權重加載成功\")\n",
        "        else:\n",
        "            print(\"未找到最佳模型權重，使用隨機初始化的模型\")\n",
        "\n",
        "        model.eval()\n",
        "        processed_data = kinematic_feature_engineering(pd.DataFrame(input_data))\n",
        "        dataset = ParkinsonDataset(processed_data)\n",
        "        loader = DataLoader(dataset, batch_size=1)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            inputs, labels = next(iter(loader))\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            probabilities = torch.softmax(outputs, dim=1).cpu().numpy()\n",
        "            if np.isnan(probabilities).any():\n",
        "                raise ValueError(\"模型輸出包含 NaN\")\n",
        "\n",
        "        return {\n",
        "            '基礎訓練': [\n",
        "                f\"手指伸展訓練: {int(probabilities[0][1]*100)}% 強度 (每日3組，每組10次)\",\n",
        "                f\"握力強化訓練: {int(probabilities[0][1]*100)}% 強度 (每日2組，每組8次)\"\n",
        "            ],\n",
        "            '高級訓練': [\n",
        "                f\"協調性訓練: {int(probabilities[0][1]*100)}% 強度 (每日1組，每組5分鐘)\",\n",
        "                \"使用壓力球進行精細動作練習\"\n",
        "            ],\n",
        "            '注意事項': [\n",
        "                \"訓練前後進行10分鐘熱敷/冷敷\",\n",
        "                \"每個動作間隔休息2分鐘\",\n",
        "                \"如出現疼痛或疲勞立即停止\"\n",
        "            ]\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"生成方案時出錯: {str(e)}\")\n",
        "        return {\"error\": \"無法生成訓練方案\"}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBqZnJrQTBqnSzGtNBJMS+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}